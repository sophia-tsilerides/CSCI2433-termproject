{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Sample Patient Unstructred Data\n",
    "\n",
    "From the Agency for Healthcare Research and Quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Web Scraping Tool\n",
    "Creating a function that web scrapes from multiple links (this is the unstructured data), parses the HTML (this is the ETL), and stores in a pandas DataFrame. The DataFrame gets convered to a CSV and a job scheduler imports it to the cloud based database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scrape_page(url):\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    # All info from webpage scraped\n",
    "    soup = BeautifulSoup(resp.text,'html.parser')\n",
    "    \n",
    "    # Scrap all text in the data\n",
    "    medrec_text = soup.find_all('p')\n",
    "    \n",
    "    # Scrap all text in tables in data\n",
    "    table_values = []\n",
    "    for line in soup.findAll('tr'):\n",
    "        for l in line.findAll('td'):\n",
    "            if l.find('sup'):\n",
    "                l.find('sup').extract()\n",
    "            table_values.append(l.getText())\n",
    "            \n",
    "    # Scrap Patient Name \n",
    "    name = medrec_text[5].get_text()\n",
    "    \n",
    "    # Scrap Patient Gender \n",
    "    gender = re.findall(r\"\\s(.*)\", table_values[15])[0]\n",
    "    \n",
    "    # Scrap Patient D.O.B \n",
    "    dob = re.findall(r\"\\s(.*)\", table_values[13])[0]\n",
    "    dob = re.findall(r\"\\s(.*)\", dob)[0]\n",
    "    \n",
    "    # Scrap Patient Race\n",
    "    race = re.findall(r\"\\s(.*)\", table_values[18])[0]\n",
    "    \n",
    "    # Scrap Patient SSN\n",
    "    ssn = re.findall(r\"\\s(.*)\", table_values[19])[0]\n",
    "    ssn = re.findall(r\"\\s(.*)\", ssn)[0]\n",
    "    ssn = re.findall(r\"\\s(.*)\", ssn)[0]\n",
    "    \n",
    "    # Scrap Patient Marital Status\n",
    "    marital_status = re.findall(r\"\\s(.*)\", table_values[16])[0]\n",
    "    marital_status = re.findall(r\"\\s(.*)\", marital_status)[0]\n",
    "    \n",
    "    # Scrap Date of Appt.\n",
    "    date = table_values[30]\n",
    "    \n",
    "    # Scrap Patient Problems\n",
    "    problems = medrec_text[7].get_text().replace(\"\\n\", \", \")\n",
    "    \n",
    "    # Scrap Patient Medication\n",
    "    medication = medrec_text[8].get_text().replace(\"\\n\", \", \")\n",
    "    \n",
    "    # Scrap Patient Directives\n",
    "    directives = medrec_text[9].get_text().replace(\"\\n\", \", \")\n",
    "    \n",
    "    # Scrap Patient Allergies\n",
    "    allergies = medrec_text[11].get_text().replace(\"\\n\", \", \")\n",
    "    \n",
    "    # Scrap Patient Services Due\n",
    "    services = medrec_text[13].get_text()\n",
    "    \n",
    "    # Scrap Patient Social history\n",
    "    social_history = re.findall(r\"\\s(.*)\", medrec_text[17].get_text())[0]\n",
    "    social_history = re.findall(r\"\\s(.*)\", social_history)[0]\n",
    "    \n",
    "    # Scrap Patient Vitals\n",
    "    first_table = table_values[45:87]\n",
    "    vitals = first_table[0::3]\n",
    "    results = first_table[1::3]\n",
    "    info = first_table[2::3]\n",
    "\n",
    "    results2 = []\n",
    "    for i in results:\n",
    "        results2.append(i.replace(\"\\xa0\", \"\"))\n",
    "\n",
    "    vitals2 = []\n",
    "    for i in vitals:\n",
    "        vitals2.append(i.replace(\"\\xa0\", \"\"))\n",
    "\n",
    "    medrec_vitals = pd.DataFrame({'vitals': vitals2, 'vitals_results': results2, \"vitals_info\": info})\n",
    "    \n",
    "    # Scrap Patient Test Results\n",
    "    last_table = table_values[97:]\n",
    "    test = []\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(last_table)):\n",
    "        if i%2!= 0:\n",
    "            results.append(last_table[i])\n",
    "        else:\n",
    "            test.append(last_table[i])\n",
    "    medrec_tests = pd.DataFrame({'test': test, 'test_results': results})\n",
    "        \n",
    "    # Creating DataFrame\n",
    "    df = pd.DataFrame([name,gender,dob,race,ssn,marital_status,date,problems,medication,directives,allergies,services,social_history]).transpose()\n",
    "    df.columns = ['Name', 'Gender', 'Date of Birth', 'Race', 'SSN','Marital Status','Date Seen','Problems','Medication', 'Directives','Allergies','Services','Social History']\n",
    "    \n",
    "    medrec_vitals = medrec_vitals.T\n",
    "    new_header = medrec_vitals.iloc[0] \n",
    "    medrec_vitals.columns = new_header \n",
    "    medrec_vitals = pd.DataFrame(medrec_vitals.iloc[1,:]).T\n",
    "    medrec_vitals = medrec_vitals.rename(index={'vitals_results':0})\n",
    "    \n",
    "    medrec_tests = medrec_tests.T\n",
    "    new_header = medrec_tests.iloc[0] \n",
    "    medrec_tests.columns = new_header \n",
    "    medrec_tests = pd.DataFrame(medrec_tests.iloc[1,:]).T\n",
    "    medrec_tests = medrec_tests.rename(index={'test_results':0})\n",
    "    \n",
    "    final_df = pd.concat([df, medrec_vitals, medrec_tests], axis=1, sort=False)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg1 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-adam-pie.html\")\n",
    "pg2 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-n-bill-windows.html\")\n",
    "pg3 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-billy-gato.html\")\n",
    "pg4 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-cherie-amore.html\")\n",
    "pg5 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-john-donut.html\")\n",
    "pg6 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-monica-latte.html\")\n",
    "pg7 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-steve-apple.html\")\n",
    "pg8 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-tom-gellato.html\")\n",
    "pg9 = web_scrape_page(\"https://www.ahrq.gov/ncepcr/tools/pf-handbook/mod8-app-b-wendy-see.html\")\n",
    "\n",
    "\n",
    "frames = [pg1, pg2, pg3, pg4, pg5, pg6, pg7, pg8, pg9]\n",
    "med_recs = pd.concat(frames)\n",
    "med_recs = med_recs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save med_recs as csv\n",
    "cwd = os.getcwd()\n",
    "output_path = cwd + '\\Med_Recs.csv'\n",
    "med_recs.to_csv(output_path, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
